{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Ldts-5RiK5",
        "outputId": "c793864d-81d5-4abd-9b97-ac2959160678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.6.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.15.1+cu118)\n",
            "Requirement already satisfied: opencv-python-headless<=4.5.4.60 in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.5.4.60)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (8.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.1)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post4)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->easyocr) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easyocr) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easyocr) (16.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (23.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-46bo_cj1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-46bo_cj1\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.3.3)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.11.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install easyocr\n",
        "! pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "! pip install opencv-python matplotlib\n",
        "! pip install wget\n",
        "! pip install onnxruntime onnx\n",
        "! pip install requests_html\n",
        "! pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKo2nd_LiEgR"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "\n",
        "#url = 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth' # vit_h link, but there's no much difference apparently in the solution\n",
        "url = 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth'\n",
        "filename = wget.download(url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Starting point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynZYN1J9LEpY",
        "outputId": "e68bbf03-b1ca-424b-aeaa-ed12c98f8aed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import imutils\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import easyocr\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "is_gpu = True if torch.cuda.is_available() else False\n",
        "reader = easyocr.Reader(['pl'], gpu=is_gpu)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IY-PXH3oHN-m"
      },
      "outputs": [],
      "source": [
        "path_books = \"./books/\"\n",
        "path_output = \"./output/\"\n",
        "if os.path.exists(path_books)==False:\n",
        "    os.mkdir(path_books)\n",
        "if os.path.exists(path_output)==False:\n",
        "    os.mkdir(path_output)\n",
        "else:\n",
        "    for filename in os.listdir(path_output):\n",
        "        file_path = os.path.join(path_output, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y2GKqM-STBj4"
      },
      "outputs": [],
      "source": [
        "def list_image_paths(folder_path):\n",
        "    # Create a list of all files with the extensions \".jpg\" and \".png\"\n",
        "    files = glob.glob(os.path.join(folder_path, \"*.jpg\")) + glob.glob(os.path.join(folder_path, \"*.png\"))\n",
        "    print(f\"Number of files: {len(files)}\")\n",
        "\n",
        "    return files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CqLttnMTJ_O",
        "outputId": "48eb28bb-25d5-41ef-86ab-1cd90154f8b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of files: 3\n"
          ]
        }
      ],
      "source": [
        "# add files you want to process to \"books\" folder\n",
        "img_paths = list_image_paths(\"./books/\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Aw4_VCec6l"
      },
      "source": [
        "# Books segmentation - SAM + Non Maximum Suppresion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iKS3vugCkbL6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
        "from segment_anything.utils.onnx import SamOnnxModel\n",
        "from skimage import measure\n",
        "\n",
        "\n",
        "import onnxruntime\n",
        "from onnxruntime.quantization import QuantType\n",
        "from onnxruntime.quantization.quantize import quantize_dynamic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WlVRQrBVjn7m"
      },
      "outputs": [],
      "source": [
        "ckp_path = \"sam_vit_l_0b3195.pth\"\n",
        "sam = sam_model_registry[\"vit_l\"](checkpoint=ckp_path)\n",
        "# move SAM to gpu sam.to(\"\")\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def nms(detections, threshold):\n",
        "    x1 = detections[:, 0]\n",
        "    y1 = detections[:, 1]\n",
        "    x2 = detections[:, 2]\n",
        "    y2 = detections[:, 3]\n",
        "    scores = detections[:, 4]\n",
        "\n",
        "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    order = np.argsort(scores)[::-1]\n",
        "\n",
        "    keep = []\n",
        "    while order.size > 0:\n",
        "        i = order[0]\n",
        "        keep.append(i)\n",
        "\n",
        "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "\n",
        "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
        "\n",
        "        overlap = (w * h) / areas[order[1:]]\n",
        "\n",
        "        inds = np.where(overlap <= threshold)[0]\n",
        "        order = order[inds + 1]\n",
        "\n",
        "    return keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#iterate through all images in the folder\n",
        "for img_path in img_paths:\n",
        "    img = cv2.imread(img_paths[0])\n",
        "    img = cv2.resize(img, (0, 0), fx = 0.2, fy = 0.2)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # enhance contrast of the image\n",
        "    img = cv2.convertScaleAbs(img, alpha=2, beta=0)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    masks = mask_generator.generate(img)\n",
        "    \n",
        "    # Extract the confidence scores from the generated masks\n",
        "    scores = [mask[\"stability_score\"] for mask in masks]\n",
        "    # Define the confidence threshold for the masks\n",
        "    confidence_threshold = 0.5\n",
        "    # Convert the generated masks to binary images\n",
        "    binary_masks = [(mask[\"segmentation\"] > confidence_threshold).astype(int) for mask in masks]\n",
        "\n",
        "    # Get the contours and bounding boxes for each binary mask\n",
        "    regions = []\n",
        "    for binary_mask in binary_masks:\n",
        "        label_image = measure.label(binary_mask)\n",
        "        region_props = measure.regionprops(label_image)\n",
        "        regions.append(region_props[0])\n",
        "    boxes = [region.bbox for region in regions]\n",
        "\n",
        "    # Create a list of detections with the bounding boxes and corresponding confidence scores\n",
        "    detections = np.hstack((np.array(boxes), np.array(scores)[:, np.newaxis]))\n",
        "    # Perform non-maximum suppression on the detections\n",
        "    nms_threshold = 0.5\n",
        "    keep = nms(detections, nms_threshold)\n",
        "    # Keep only the detections that were not suppressed\n",
        "    if len(keep) > 0:\n",
        "        detections = detections[keep]\n",
        "    else:\n",
        "        detections = []\n",
        "\n",
        "    # Keep only the boxes and scores that were not suppressed\n",
        "    boxes = [boxes[i] for i in keep]\n",
        "    scores = [scores[i] for i in keep]\n",
        "    \n",
        "    # If one dimention of the box is bigger than another at least 3 times tha another one, then it is a book page and we keep it, otherwise we discard it. \n",
        "    # If the area of the box is smallet than 1/45 of the image, we discard it as well.\n",
        "    # Create a list of boxes that are likely to be book pages\n",
        "    book_page_boxes = []\n",
        "    for box in boxes:\n",
        "        if (box[2] - box[0]) > 3.5 * (box[3] - box[1]) and (box[2] - box[0]) * (box[3] - box[1]) > (img.shape[0] * img.shape[1]) / 50:\n",
        "            book_page_boxes.append(box)\n",
        "        elif (box[3] - box[1]) > 3.5 * (box[2] - box[0]) and (box[2] - box[0]) * (box[3] - box[1]) > (img.shape[0] * img.shape[1]) / 55:\n",
        "            book_page_boxes.append(box)\n",
        "        else:\n",
        "            continue\n",
        "        \n",
        "    # put the boxes on the image of original size (from image_path) and make sure the book_page_boxes coordinates are resized from the resized image to the original image\n",
        "    # Show the image with the detections\n",
        "    resized_img = img.copy()\n",
        "    img_original = cv2.imread(img_path)\n",
        "    img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
        "    img_original_copy = img_original.copy()\n",
        "\n",
        "    scale_1 = img_original.shape[0] / resized_img.shape[0]\n",
        "    scale_2 = img_original.shape[1] / resized_img.shape[1]\n",
        "\n",
        "    #crop the book pages from the original image and save to output folder with name of original file name and index\n",
        "    for i, box in enumerate(book_page_boxes):\n",
        "        box = [int(box[0] * scale_1), int(box[1] * scale_2), int(box[2] * scale_1), int(box[3] * scale_2)]\n",
        "        #img_original = cv2.rectangle(img_original_copy, (box[1], box[0]), (box[3], box[2]), (255, 0, 0), 2)\n",
        "        crop_img = img_original[box[0]:box[2], box[1]:box[3]]\n",
        "        cv2.imwrite(os.path.join(path_output, os.path.basename(img_path).split(\".\")[0] + \"_\" + str(i) + \".jpg\"), crop_img)\n",
        "            \n",
        "    #plt.figure(figsize=(10, 10))\n",
        "    #plt.imshow(img_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Create a copy of the original image to draw the detections on\\nimg_copy = img.copy()\\n\\n# Draw the detections as bounding boxes on the image\\nfor box in boxes:\\n    cv2.rectangle(img_copy, (box[1], box[0]), (box[3], box[2]), (255, 0, 0), 2)\\n    \\n# Show the image with the detections\\nplt.figure(figsize=(10, 10))\\nplt.imshow(img_copy)\\nplt.show()\\n'"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Create a copy of the original image to draw the detections on\n",
        "img_copy = img.copy()\n",
        "\n",
        "# Draw the detections as bounding boxes on the image\n",
        "for box in boxes:\n",
        "    cv2.rectangle(img_copy, (box[1], box[0]), (box[3], box[2]), (255, 0, 0), 2)\n",
        "    \n",
        "# Show the image with the detections\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_copy)\n",
        "plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdyjioBhmXAD"
      },
      "source": [
        "### Image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "def image_smoothening(img):\n",
        "    ret1, th1 = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY)\n",
        "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    blur = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return th3\n",
        "\n",
        "def img_preprocess(file_name):\n",
        "    img = cv2.imread(file_name)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 3)\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
        "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
        "    smoothening = image_smoothening(img)\n",
        "    ocr_image = cv2.bitwise_or(smoothening, closing)\n",
        "    \n",
        "    #make image to white and black\n",
        "    ocr_image = cv2.threshold(ocr_image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "    # if there are white letters with black countour, make them black and countour white\n",
        "    cv2.imwrite(file_name, ocr_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "er7A15Pkcx-O"
      },
      "outputs": [],
      "source": [
        "def check_upside_down(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    org_img_text = reader.readtext(img)\n",
        "    rotated_img = imutils.rotate_bound(img, 180)\n",
        "    rotated_img_txt = reader.readtext(rotated_img)\n",
        "    count_original = sum(len(element[-2])*element[-1] for element in org_img_text)\n",
        "    count_rotated = sum(len(element[-2])*element[-1] for element in rotated_img_txt)\n",
        "\n",
        "\n",
        "    if count_original < count_rotated:\n",
        "        cv2.imwrite(img_path, rotated_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "rioB7ngq1dDE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of files: 20\n"
          ]
        }
      ],
      "source": [
        "img_paths_cropped = list_image_paths(\"./output/\")\n",
        "for img_path in img_paths_cropped:\n",
        "    img_preprocess(img_path)\n",
        "    check_upside_down(img_path)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "011gU1aoy8Xy"
      },
      "source": [
        "# Try easyOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mqvCHao0MC5S"
      },
      "outputs": [],
      "source": [
        "def recognize_text(img_path):\n",
        "    return reader.readtext(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "RCPUBsNGMC_d"
      },
      "outputs": [],
      "source": [
        "def overlay_ocr_text(img_path):\n",
        "    '''loads an image, recognizes text, and overlays the text on the image.'''\n",
        "    # loads image\n",
        "    img = cv2.imread(img_path)\n",
        "    result = recognize_text(img_path)\n",
        "    text_all = [img_path]\n",
        "\n",
        "    not_recognized = 0\n",
        "    # if OCR prob is over 0.5, overlay bounding box and text\n",
        "    for (bbox, text, prob) in result:\n",
        "        if prob >= 0.5:\n",
        "            text_all.append(text)\n",
        "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
        "            \n",
        "\n",
        "    if len(text_all)==1:\n",
        "        #reverse image\n",
        "        img = cv2.bitwise_not(img)\n",
        "        cv2.imwrite(img_path, img)\n",
        "        result = recognize_text(img_path)\n",
        "        for (bbox, text, prob) in result:\n",
        "            if prob >= 0.45:\n",
        "                text_all.append(text)\n",
        "        \n",
        "    if len(text_all)==1:\n",
        "        text_all.append(\"NIE_ROZPOZNANO_TYTUŁU\")\n",
        "        return text_all\n",
        "    \n",
        "    return text_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "7MhrLzGBM66E"
      },
      "outputs": [],
      "source": [
        "with open(\"text.txt\", \"w\") as txt_file:\n",
        "    for im_path in img_paths_cropped:\n",
        "        text = overlay_ocr_text(im_path)\n",
        "        text_str = ' '.join(text)\n",
        "        txt_file.write(text_str)\n",
        "        txt_file.write(\"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nqwhc1Skt7mP"
      },
      "source": [
        "# Web scrapping for the title/author"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "P0wYNaP-0zEw"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import urllib\n",
        "import pandas as pd\n",
        "from requests_html import HTML\n",
        "from requests_html import HTMLSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "yA5QdxrVuIn7"
      },
      "outputs": [],
      "source": [
        "def get_source(url):\n",
        "    #Return the source code for the provided URL.\n",
        "    try:\n",
        "        session = HTMLSession()\n",
        "        response = session.get(url)\n",
        "        return response\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(e)\n",
        "        \n",
        "def get_results(query):\n",
        "    query = urllib.parse.quote_plus(query)\n",
        "    response = get_source(\"https://www.google.pl/search?q=\" + query)\n",
        "    return response\n",
        "\n",
        "def parse_results(response):\n",
        "    css_identifier_result = \".tF2Cxc\"\n",
        "    css_identifier_title = \"h3\"\n",
        "    css_identifier_link = \".yuRUbf a\"\n",
        "    css_identifier_text = \".VwiC3b\"\n",
        "    results = response.html.find(css_identifier_result)\n",
        "    output = []\n",
        "    \n",
        "    for result in results:\n",
        "        item = {\n",
        "            'title': result.find(css_identifier_title, first=True).text,\n",
        "            'link': result.find(css_identifier_link, first=True).attrs['href']\n",
        "        }\n",
        "        output.append(item)\n",
        "        \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "ulPO7FyhvBfJ"
      },
      "outputs": [],
      "source": [
        "def google_search(query):\n",
        "    response = get_results(query)\n",
        "    return parse_results(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "CorJuQUOC-Zz"
      },
      "outputs": [],
      "source": [
        "with open('text.txt') as f:\n",
        "    all_books = f.readlines()\n",
        "\n",
        "img_path = []\n",
        "queries = []\n",
        "for i in range(len(all_books)): \n",
        "    book = all_books[i].split(\" \", 1)\n",
        "    #remove \\n from title\n",
        "    book[1] = book[1].rstrip()\n",
        "    img_path.append(book[0])\n",
        "    queries.append(book[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"titles.txt\", \"w\") as txt_file:\n",
        "    for i in range(len(queries)):\n",
        "        result = google_search(str(\"książka\" + queries[i]))\n",
        "        if result == []:\n",
        "            txt_file.write(img_path[i])\n",
        "            txt_file.write(\"; \")\n",
        "            txt_file.write(\"Google: NIE ZNALEZIONO TYTUŁU\")\n",
        "            txt_file.write(\"; \")\n",
        "            txt_file.write(queries[i])\n",
        "            txt_file.write(\"\\n\")\n",
        "            continue\n",
        "        else:\n",
        "            txt_file.write(img_path[i])\n",
        "            txt_file.write(\"; \")\n",
        "            title = result[0]['title']\n",
        "            txt_file.write(title)\n",
        "            txt_file.write(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
